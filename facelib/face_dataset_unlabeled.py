# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/61_face_dataset_unlabeled.ipynb (unless otherwise specified).

__all__ = ['read_dict', 'save_dict', 'expression_map_default', 'gender_map_default', 'icao_map_default',
           'properties_map_default', 'lbl_config', 'icao_warnings', 'config', 'FACE_PATH', 'PATH', 'IM_PATH', 'DNAMES',
           'pry_lbl2int', 'pitch_roll_yaw_mean', 'pitch_roll_yaw_std', 'get_filename2bboxes_dict', 'create_df',
           'get_filename2cropped_dict', 'create_cropped_data']

# Cell
from fastai import *
from fastai.vision import *
from pathlib import Path
import cv2

# Cell
import pickle

def read_dict(path):
    with open(path, 'rb') as handle:
        unserialized_data = pickle.load(handle)
    return unserialized_data

def save_dict(dictionary, path):
    with open(path, 'wb') as handle:
        pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)

# Cell
# if value is None then it is skipped
expression_map_default = {
    'Unspecified': 0,
    'Neutral': 1,
    'Smile': 2,
    'SmileOpenedJaw': 3,
    'RaisedBrows': 4,
    'EyesAway': 5,
    'Squinting': 6,
    'Frowning': 7,
    'Unknown': 0
}
gender_map_default = {
    'Unspecified': 0,
    'Unknown': 0,
    'Male': 1,
    'Female': 2
}
icao_map_default = {
    'None': 0,
    'FaceNotDetected': 1,
    'RollLeft': 2,'RollRight': 3,'YawLeft': 4,'YawRight': 5,'PitchUp': 6,'PitchDown': 7,
    'TooNear': 8,'TooFar': 9,'TooNorth': 10,'TooSouth': 11,'TooEast': 12,'TooWest': 13,
    'Sharpness': 14,
    'BackgroundUniformity': 15,
    'GrayscaleDensity': 16,
    'Saturation': 17,
    'Expression': 18,
    'DarkGlasses':19,
    'Blink': 20,
    'MouthOpen': 21,
    'LookingAway': 22,
    'RedEye': 23,
    'FaceDarkness': 24,
    'UnnaturalSkinTone': 25,
    'WashedOut': 26,
    'Pixelation': 27,
    'SkinReflection': 28,
    'GlassesReflection': 29
}
properties_map_default = {
    'NotSpecified': 0,
    'Specified': 0,
    'Glasses': 1,
    'Mustache': 2,
    'Beard': 3,
    'TeethVisible': 4,
    'Blink': 5,
    'MouthOpen': 6,
    'LeftEyePatch': 7,
    'RightEyePatch': 8,
    'BothEyePatch': 9,
    'DarkGlasses': 10,
    'DistortingCondition': 11,
    'Hat': 12,
    'Scarf': 13,
    'NoEar': 14
}

# Cell
# format: (type,default_number,...)
# default_number: if number == 254 and is scalar: then swap it with this number
#   if number is multi: then this value is a map from values to labels {'1': 'true', '2': 'unknown', '3': 'true',...}
lbl_config = {
 'Age': ('scalar', 1, 2),
 'BackgroundUniformity': ('scalar', 1, 2),
 'BeardConfidence': ('scalar', 1, 2),
 'BlinkConfidence': ('scalar', 1, 2),
 'Contrast': ('scalar', 1, 2),
 'DarkGlassesConfidence': ('scalar', 1, 2),
 'DetectionConfidence': ('scalar', 1, 2),
 'EmotionAngerConfidence': ('scalar', 1, 2),
 'EmotionContemptConfidence': ('scalar', 1, 2),
 'EmotionDisgustConfidence': ('scalar', 1, 2),
 'EmotionFearConfidence': ('scalar', 1, 2),
 'EmotionHappinessConfidence': ('scalar', 1, 2),
 'EmotionNeutralConfidence': ('scalar', 1, 2),
 'EmotionSadnessConfidence': ('scalar', 1, 2),
 'EmotionSurpriseConfidence': ('scalar', 1, 2),
 'EthnicityAsianConfidence': ('scalar', 1, 2),
 'EthnicityBlackConfidence': ('scalar', 1, 2),
 'EthnicityHispanicConfidence': ('scalar', 1, 2),
 'EthnicityIndianConfidence': ('scalar', 1, 2),
 'EthnicityWhiteConfidence': ('scalar', 1, 2),
 'ExpressionConfidence': ('scalar', 1, 2),
 'FaceDarknessConfidence': ('scalar', 1, 2),
 'GenderConfidence': ('scalar', 1, 2),
 'GlassesConfidence': ('scalar', 1, 2),
 'GlassesReflectionConfidence': ('scalar', 1, 2),
 'GrayscaleDensity': ('scalar', 1, 2),
 'HatConfidence': ('scalar', 1, 2),
 'LivenessScore': ('scalar', 1, 2),
 'LivenessTargetPitch': ('scalar', 1, 2),
 'LivenessTargetYaw': ('scalar', 1, 2),
 'LookingAwayConfidence': ('scalar', 1, 2),
 'MouthOpenConfidence': ('scalar', 1, 2),
 'MustacheConfidence': ('scalar', 1, 2),
 'Noise': ('scalar', 1, 2),
 'Pitch': ('scalar float', 1, 2),
 'PixelationConfidence': ('scalar', 1, 2),
 'Quality': ('scalar', 1, 2),
 'RedEyeConfidence': ('scalar', 0, 2),
 'Roll': ('scalar float', 1, 2),
 'Saturation': ('scalar', 1, 2),
 'Sharpness': ('scalar', 1, 2),
 'SkinReflectionConfidence': ('scalar', 1, 2),
 'UnnaturalSkinToneConfidence': ('scalar', 1, 2),
 'WashedOutConfidence': ('scalar', 1, 2),
 'Yaw': ('scalar float', 1, 2),
 'Expression': ('multi', expression_map_default, 2),
 'Gender': ('multi', gender_map_default, 2),
 'IcaoWarnings': ('multi', icao_map_default, 2),
 'LivenessAction': ('multi', None, 2),
 'Properties': ('multi', properties_map_default, 2),
 'BoundingRect': ('bbox', 1, 2),
 'FeaturePoints': ('pts', 1, 2),
 'LeftEyeCenter': ('pt', 1, 2),
 'MouthCenter': ('pt', 1, 2),
 'NoseTip': ('pt', 1, 2),
 'RightEyeCenter': ('pt', 1, 2)
}

# Cell
icao_warnings = [
 'TooSouth',
 'TooFar',
 'RedEye',
 'YawRight',
 'TooEast',
 'SkinReflection',
 'UnnaturalSkinTone',
 'MouthOpen',
 'RollRight',
 'TooNear',
 'RollLeft',
 'Sharpness',
 'None',
 'TooNorth',
 'DarkGlasses',
 'GrayscaleDensity',
 'PitchDown',
 'Blink',
 'FaceDarkness',
 'LookingAway',
 'GlassesReflection',
 'WashedOut',
 'Expression',
 'Saturation',
 'TooWest',
 'Pixelation',
 'YawLeft',
 'PitchUp'
]

# Cell
class config:
    DICT_PATH = "../data/face/unlabeled_fn2label.pkl"
    FACE_PATH = Path("/data/faces/")
    PATH = FACE_PATH/"unlabeled"
    IM_PATH = PATH/"images"
    CROPPED_IM_PATH = Path("../data/face/unlabeled_cropped_images/")
    CROPPED_DICT_PATH = Path("../data/face/unlabeled_cropped_fn2label.pkl")

# Cell
FACE_PATH = Path("/data/faces/")
PATH = FACE_PATH/"unlabeled"
IM_PATH = PATH/"images"
DNAMES = ['sof', 'lfw', 'fc', 'bioid', 'wiki']

# Cell
pry_lbl2int = {'Pitch': 0, 'Roll': 1, 'Yaw': 2}
pitch_roll_yaw_mean = tensor([-8,0,0])
pitch_roll_yaw_std = tensor([6,6,8])

# Cell
def get_filename2bboxes_dict():
    return read_dict(config.DICT_PATH)

# Cell
def create_df():
    fn2labels = get_filename2bboxes_dict()
    data = []
    for fn in fn2labels.keys():
        data.append((str(config.IM_PATH/fn), False, 'unlabeled'))
    return pd.DataFrame(data, columns=['image_path', 'valid', 'dataset'])

# Cell
def get_filename2cropped_dict():
    return read_dict(config.CROPPED_DICT_PATH)

# Cell
def create_cropped_data():
    fn2labels = get_filename2cropped_dict()
    data = []
    for fn in fn2labels.keys():
        data.append((str(config.CROPPED_IM_PATH/fn), False, 'unlabeled_cropped'))
    return pd.DataFrame(data, columns=['image_path', 'valid', 'dataset']), fn2labels